import faiss
import numpy as np
import json
import logging
from sentence_transformers import SentenceTransformer

# ConfiguraciÃ³n
DATASET_PATH = "/home/cestel/datasets/dataset_faiss_entidades.jsonl"
FAISS_INDEX_PATH = "faiss_index_entidades.bin"  # Cambia el nombre para diferenciarlo del anterior

# Configurar logging
logging.basicConfig(level=logging.INFO)

# Cargar el modelo SentenceTransformer
logging.info("ğŸ”¹ Cargando modelo SentenceTransformer...")
modelo = SentenceTransformer("all-MiniLM-L6-v2")  # ğŸ† Mejor para bÃºsqueda semÃ¡ntica
#modelo = SentenceTransformer("all-mpnet-base-v2")  # ğŸ† Mejor para bÃºsqueda semÃ¡ntica
logging.info("âœ… Modelo SentenceTransformer cargado correctamente.")

# Cargar dataset de preguntas y respuestas
logging.info("ğŸ”¹ Cargando dataset...")
dataset = []
try:
    with open(DATASET_PATH, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            dataset.append(json.loads(line))
    logging.info(f"âœ… Dataset cargado con {len(dataset)} preguntas.")
except Exception as e:
    logging.error(f"âŒ Error cargando el dataset: {str(e)}")
    exit(1)

# Generar embeddings con SentenceTransformer
logging.info("ğŸ”¹ Generando embeddings...")
preguntas = [entry["prompt"] for entry in dataset]
embeddings = modelo.encode(preguntas, convert_to_numpy=True)  # âœ… Correcto para ST
logging.info(f"âœ… Embeddings generados con forma {embeddings.shape}.")

# Crear Ã­ndice FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)  # Ãndice con distancia L2
index.add(embeddings)
logging.info(f"âœ… Ãndice FAISS creado con {index.ntotal} embeddings.")

# Guardar el Ã­ndice en un archivo
faiss.write_index(index, FAISS_INDEX_PATH)
logging.info(f"âœ… Ãndice guardado en {FAISS_INDEX_PATH}.")

logging.info("ğŸš€ FAISS listo para su uso con SentenceTransformer!")
